{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учебное соревнование kaggle по классификации персонажей из Симпсонов.\n",
    "\n",
    "https://www.kaggle.com/c/journey-springfield/overview\n"
   ]
  },
  {
   "attachments": {
    "ea480148-cf9b-452d-bfbc-1d847abb6384.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![изображение.png](attachment:ea480148-cf9b-452d-bfbc-1d847abb6384.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)\n",
    "\n",
    "    \n",
    "def fit_epoch(model, train_loader, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "              \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def train(train_files, val_files, model, epochs, batch_size):\n",
    "    train_loader = DataLoader(train_files, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val_files, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        #opt = torch.optim.Adam(model.parameters())\n",
    "        opt = torch.optim.AdamW(model.parameters(), amsgrad=True)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n",
    "            print(\"loss\", train_loss)\n",
    "            \n",
    "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
    "            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            \n",
    "    return history\n",
    "\n",
    "\n",
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "    \n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "def predict_one_sample(model, inputs, device=DEVICE):\n",
    "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        model.eval()\n",
    "        logit = model(inputs).cpu()\n",
    "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конструкторе класса я переопределил загрузку картинок, добавив аугментацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "        self.len_ = len(self.files)     \n",
    "        self.label_encoder = LabelEncoder()\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':            \n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomAffine(degrees=10),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ])        \n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ])\n",
    "        \n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = transform(x)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "\n",
    "TRAIN_DIR = Path('train/dataset')\n",
    "TEST_DIR = Path('test/testset')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
    "                                          stratify=train_val_labels)\n",
    "\n",
    "val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "train_dataset = SimpsonsDataset(train_files, mode='train')\n",
    "train_val_dataset = SimpsonsDataset(train_val_files, mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать Transfer Learning, в качестве предобученной модели возьмем resnet50.\n",
    "Оставим размороженными последние 2 слоя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will classify :42\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(train_val_labels))\n",
    "model = models.resnet50(pretrained=True).to(DEVICE)\n",
    "print(\"we will classify :{}\".format(n_classes))\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# замораживаем веса всех слоев\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# размораживаем 2 последних слоя\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n",
    "num_features = 2048\n",
    "\n",
    "# Заменяем Fully-Connected слой на наш линейный классификатор\n",
    "model.fc = nn.Linear(num_features, n_classes).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучалась сетами по 10-20 эпох, затем веса сохранялись и модель доучивалась.\n",
    "На выводе обучения модели видны последние 10 эпох обучения 60-70. Для воспроизводимости можно запустить модель с 60 или 70 эпохами, результат на каггле был идентичен."
   ]
  },
  {
   "attachments": {
    "ea480148-cf9b-452d-bfbc-1d847abb6384.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![изображение.png](attachment:ea480148-cf9b-452d-bfbc-1d847abb6384.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.054849769383687054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  10%|███████▌                                                                   | 1/10 [03:12<28:53, 192.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: 0.0548     val_loss 0.0198 train_acc 0.9843 val_acc 0.9950\n",
      "loss 0.049049857777005317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  20%|███████████████                                                            | 2/10 [06:24<25:38, 192.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 002 train_loss: 0.0490     val_loss 0.0234 train_acc 0.9858 val_acc 0.9929\n",
      "loss 0.03918733602132279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  30%|██████████████████████▌                                                    | 3/10 [09:34<22:22, 191.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 003 train_loss: 0.0392     val_loss 0.0291 train_acc 0.9894 val_acc 0.9918\n",
      "loss 0.029496085015709165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  40%|██████████████████████████████                                             | 4/10 [12:45<19:09, 191.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 004 train_loss: 0.0295     val_loss 0.0173 train_acc 0.9908 val_acc 0.9960\n",
      "loss 0.04007536094219743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  50%|█████████████████████████████████████▌                                     | 5/10 [15:58<15:59, 191.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 005 train_loss: 0.0401     val_loss 0.0525 train_acc 0.9882 val_acc 0.9868\n",
      "loss 0.04273248182370996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  60%|█████████████████████████████████████████████                              | 6/10 [19:52<13:38, 204.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 006 train_loss: 0.0427     val_loss 0.0587 train_acc 0.9876 val_acc 0.9822\n",
      "loss 0.03389413569507886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  70%|████████████████████████████████████████████████████▌                      | 7/10 [23:30<10:25, 208.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 007 train_loss: 0.0339     val_loss 0.0082 train_acc 0.9906 val_acc 0.9981\n",
      "loss 0.020292498155344344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  80%|████████████████████████████████████████████████████████████               | 8/10 [26:53<06:53, 206.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 008 train_loss: 0.0203     val_loss 0.0064 train_acc 0.9935 val_acc 0.9979\n",
      "loss 0.04187874787322372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [30:15<03:25, 205.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 009 train_loss: 0.0419     val_loss 0.0103 train_acc 0.9881 val_acc 0.9969\n",
      "loss 0.02175431690847115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [33:31<00:00, 201.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 010 train_loss: 0.0218     val_loss 0.0161 train_acc 0.9939 val_acc 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = train(train_val_dataset, val_dataset, model=model, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"./_models/resnet50_2_70epoche_weights.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(map(int, np.random.uniform(0, 1000, 20)))\n",
    "imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n",
    "\n",
    "probs_ims = predict(model, imgs)\n",
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "y_pred = np.argmax(probs_ims, -1)\n",
    "actual_labels = [val_dataset[id][1] for id in idxs]\n",
    "preds_class = list(y_pred)\n",
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "probs = predict(model, test_loader)\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
    "test_filenames = [path.name for path in test_dataset.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submit = pd.DataFrame({'ID': test_filenames, 'Expected': preds})\n",
    "my_submit.to_csv('./_answers/resnet50_2_70.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
